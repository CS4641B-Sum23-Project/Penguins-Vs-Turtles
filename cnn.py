# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUHel0Ww1RrH0ji51dQlg7m7KhHtpfDU
"""

# Commented out IPython magic to ensure Python compatibility.

#Import dependencies
import tensorflow as tf
import os
import matplotlib.pyplot as plt
import cv2
import imghdr
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy
from tensorflow.keras.models import load_model

#Will need to edit this later to reflect path
SCRIPT_DIR       = os.path.dirname(os.path.abspath(__file__))
TRAIN_ANNOTE_PTH = os.path.join(SCRIPT_DIR, 'train_annotations')
VALID_ANNOTE_PTH = os.path.join(SCRIPT_DIR, 'valid_annotations')
IMAGE_DIR        = os.path.join(SCRIPT_DIR, 'images')
TRAIN_IMAGES_DIR = os.path.join(IMAGE_DIR, 'training')
VALID_IMAGES_DIR = os.path.join(IMAGE_DIR, 'validation')
EXTRACTED_BB_DIR = os.path.join(IMAGE_DIR, 'extracted')
DATA_DIR         = os.path.join(SCRIPT_DIR, 'data')

BB_TRAIN_IMAGES_DIR = os.path.join(EXTRACTED_BB_DIR, 'training')
BB_VALID_IMAGES_DIR = os.path.join(EXTRACTED_BB_DIR, 'validation')
IMG_DATA_PKL_NAME   = 'image_data.pkl'
IMG_DATA_PKL_PTH    = os.path.join(DATA_DIR, IMG_DATA_PKL_NAME)

# Preprocessing
data_dir = 'data'
image_exts = ['jpeg','jpg', 'bmp', 'png']

# Remove dodgy images
for image_class in os.listdir(data_dir):
    for image in os.listdir(os.path.join(data_dir, image_class)):
        image_path = os.path.join(data_dir, image_class, image)
        try:
            img = cv2.imread(image_path)
            tip = imghdr.what(image_path)
            if tip not in image_exts:
                print('Image not in ext list {}'.format(image_path))
                os.remove(image_path)
        except Exception as e:
            print('Issue with image {}'.format(image_path))
            # os.remove(image_path)

# Load data
data = tf.keras.utils.image_dataset_from_directory('data')
data_iterator = data.as_numpy_iterator()
batch = data_iterator.next()
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])

# Scale data
data = data.map(lambda x,y: (x/255, y))
data.as_numpy_iterator().next()

# Split data
train_size = int(len(data)*.7)
val_size = int(len(data)*.2)
test_size = int(len(data)*.1)

train_size

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)

# Initializing model
model = Sequential()

# Model architecture
model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())

model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(256, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Summary
model.summary()

# Training
logdir='logs'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)
hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])

# Model Plots
fig = plt.figure()
plt.plot(hist.history['loss'], color='teal', label='loss')
plt.plot(hist.history['val_loss'], color='orange', label='val_loss')
fig.suptitle('Loss', fontsize=20)
plt.legend(loc="upper left")
plt.show()

fig = plt.figure()
plt.plot(hist.history['accuracy'], color='teal', label='accuracy')
plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()

# Performance Evaluation
pre = Precision()
re = Recall()
acc = BinaryAccuracy()

for batch in test.as_numpy_iterator():
    X, y = batch
    yhat = model.predict(X)
    pre.update_state(y, yhat)
    re.update_state(y, yhat)
    acc.update_state(y, yhat)

print(pre.result(), re.result(), acc.result())

# Performance on Testing Partition
img = cv2.imread('image_id_000.jpg')
plt.imshow(img)
plt.show()

resize = tf.image.resize(img, (256,256))
plt.imshow(resize.numpy().astype(int))
plt.show()

# Testing on New Data
yhat = model.predict(np.expand_dims(resize/255, 0))
yhat

if yhat > 0.5:
    print(f'Predicted class is Turtle')
else:
    print(f'Predicted class is Penguin')

# Matrix

# Saving model
model.save(os.path.join('models','imageclassifier.h5'))
new_model = load_model('imageclassifier.h5')
new_model.predict(np.expand_dims(resize/255, 0))